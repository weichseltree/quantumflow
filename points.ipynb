{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab8ebd-a544-4e10-a721-2e538cc94f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "np.set_printoptions(precision=2, linewidth=200, suppress=True)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from itertools import permutations, combinations\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "num_points = 24\n",
    "dim = 2\n",
    "max_error = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a0de23-f7d8-4a68-b673-e8a842c3df7a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Function to generate random points in 2D space\n",
    "def generate_random_points(num_points, space_size=(100, 100)):\n",
    "    return np.random.rand(num_points, 2) * space_size\n",
    "\n",
    "def initialize_grid(num_points, grid_size=100):\n",
    "    \"\"\"\n",
    "    Initialize a grid pattern with a quadratic number of points.\n",
    "\n",
    "    Parameters:\n",
    "    - num_points (int): Total number of points, must be a perfect square.\n",
    "    - grid_size (float): The size of the grid (length of one side).\n",
    "\n",
    "    Returns:\n",
    "    - points (np.ndarray): A numpy array of shape (num_points, 2) representing the grid points.\n",
    "    \"\"\"\n",
    "    # Check if num_points is a perfect square\n",
    "    grid_side = int(np.sqrt(num_points))\n",
    "    if grid_side ** 2 != num_points:\n",
    "        raise ValueError(\"num_points must be a perfect square\")\n",
    "\n",
    "    # Create the grid points\n",
    "    x = np.linspace(0, grid_size, grid_side)\n",
    "    y = np.linspace(0, grid_size, grid_side)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    \n",
    "    # Combine the x and y coordinates into a single array\n",
    "    points = np.column_stack([xv.ravel(), yv.ravel()])\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9aafe2-7a3c-4a26-b5fa-d0a1b3484339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_triu_indices(n, k=1):\n",
    "    a1, a2 = np.triu_indices(n, k=k)\n",
    "    return np.flip(n - 1 - a2), np.flip(n - 1 - a1)\n",
    "\n",
    "# Function to calculate pairwise Euclidean distances\n",
    "def distance_matrix(points):\n",
    "    return np.sqrt(np.sum((points[:, np.newaxis, :] - points[np.newaxis, :, :]) ** 2, axis=-1))\n",
    "\n",
    "\n",
    "def calculate_distances(points):\n",
    "    distances = distance_matrix(points)\n",
    "    i, j = np.triu_indices(points.shape[0], 1)\n",
    "    return -np.sort(-distances[i, j])\n",
    "    \n",
    "#@jit\n",
    "def loss_function(points, target_distances):\n",
    "    \"\"\"Calculate the mean squared error between sorted guessed distances and sorted target distances.\"\"\"\n",
    "    distances = calculate_distances(points)\n",
    "    return np.mean((distances - target_distances) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c683703d-9233-4762-9a64-361137fde54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to align point cloud to a standard reference frame\n",
    "def align_to_reference_frame(points, return_fn=False):\n",
    "    # Calculate the center of the point cloud\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    \n",
    "    # Translate the point cloud to the origin\n",
    "    translated_points = points - centroid\n",
    "    \n",
    "    # Perform PCA to find the principal components\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(translated_points)\n",
    "    \n",
    "    # Rotate points so that the largest eigenvector aligns with the x-axis\n",
    "    rotated_points = pca.transform(translated_points)\n",
    "\n",
    "    def transform_points(points):\n",
    "        return np.concatenate([pca.transform(points[:, :len(centroid)] - centroid), points[:, len(centroid):]], axis=-1)\n",
    "\n",
    "    if return_fn:\n",
    "        return rotated_points, transform_points\n",
    "    else:\n",
    "        return rotated_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c231d6c5-3728-464f-8b19-4634ceca9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical MDS\n",
    "def mds(distance_matrix, n, dim=2):\n",
    "    D_squared = distance_matrix ** 2\n",
    "    J = np.eye(n) - np.ones((n, n)) / n\n",
    "    B = -0.5 * J @ D_squared @ J\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(B)\n",
    "    return eigenvectors[:, -dim:] @ np.diag(np.sqrt(eigenvalues[-dim:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06467df-1de4-4723-9a04-e8a87d747cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize 10 random points\n",
    "original_points = generate_random_points(num_points)\n",
    "#original_points = initialize_grid(num_points)\n",
    "\n",
    "original_points = align_to_reference_frame(original_points)\n",
    "print(\"Original Points:\", original_points.shape)\n",
    "print(original_points)\n",
    "print()\n",
    "\n",
    "# Convert their absolute coordinates into relative distances\n",
    "sorted_distances = calculate_distances(original_points)\n",
    "print(sorted_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72361e62-c404-4b29-affd-cd05dc019aab",
   "metadata": {},
   "source": [
    "# Trigonometry with checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecd71b-8ff2-417b-9c85-f57a86fbb6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_third_points_vectorized(d1, d2, max_distance):\n",
    "    \"\"\"Calculate the possible positions for the third points using vectorized operations.\"\"\"\n",
    "    x1 = max_distance / 2\n",
    "    x2 = -max_distance / 2\n",
    "    \n",
    "    # Calculate the x-coordinate of the third points\n",
    "    x3 = (d1**2 - d2**2) / (2 * max_distance)\n",
    "    \n",
    "    # Calculate the y-coordinate squared\n",
    "    y3_squared = d1**2 - (x3 + x1)**2\n",
    "    \n",
    "    # Mask out invalid solutions (negative y3_squared)\n",
    "    mask = y3_squared >= 0\n",
    "    x3 = x3[mask]\n",
    "    y3 = np.sqrt(y3_squared[mask])\n",
    "    \n",
    "    return np.column_stack((x3, y3)), mask\n",
    "\n",
    "def pairs_of_pairs(valid_edges):\n",
    "    triangle_distance_indices, candidate_distance_indices = [], []\n",
    "    \n",
    "    for k, edge1 in enumerate(valid_edges): #tqdm(enumerate(valid_edges), total=len(valid_edges)):\n",
    "        for l, edge2 in enumerate(valid_edges):\n",
    "            if np.any(edge1[np.newaxis, :] == edge2[:, np.newaxis]): continue\n",
    "            yield k, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc805d-5cbe-476c-bc51-ec2705cd14a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_quadrilateral(sorted_distances):\n",
    "    max_distance = sorted_distances[0]\n",
    "    \n",
    "    # Generate all pairs of distances\n",
    "    i, j = np.triu_indices(len(sorted_distances) - 1, k=1)\n",
    "    i += 1\n",
    "    j += 1\n",
    "    d1, d2 = sorted_distances[i], sorted_distances[j]\n",
    "    \n",
    "    possible_positions, mask = calculate_third_points_vectorized(d1, d2, max_distance)\n",
    "    #print(possible_positions)\n",
    "    valid_edges = np.stack([i[mask], j[mask]], axis=1)\n",
    "    \n",
    "    reconstructed_points = np.stack([[max_distance / 2, 0], [-max_distance / 2, 0]])\n",
    "    \n",
    "    if len(reconstructed_points) == 2:\n",
    "        for k, l in pairs_of_pairs(valid_edges):\n",
    "            match_indices = np.setdiff1d(np.arange(len(sorted_distances) - 1) + 1, np.concatenate([valid_edges[k], valid_edges[l]]))\n",
    "            \n",
    "            pos1, pos2 = possible_positions[k], possible_positions[l]\n",
    "            pos2 = np.stack([pos2, np.stack([-pos2[0], pos2[1]], axis=-1), np.stack([pos2[0], -pos2[1]], axis=-1), -pos2])\n",
    "            \n",
    "            #print('pos1\\n', pos1)\n",
    "            #print('pos2\\n', pos2)\n",
    "            \n",
    "            possible_distances = np.sqrt(np.sum((pos1[np.newaxis, :] - pos2) ** 2, axis=-1))\n",
    "            #print('possible_distances\\n', possible_distances)\n",
    "            \n",
    "            #print('sorted_distances\\n', sorted_distances[match_indices])\n",
    "            distance_errors = np.abs(possible_distances - sorted_distances[match_indices][:, np.newaxis])\n",
    "            #print('distance_errors\\n', distance_errors)\n",
    "            \n",
    "            smallest_index = np.argmin(distance_errors)\n",
    "            smallest_indices = np.unravel_index(smallest_index, distance_errors.shape)\n",
    "            error = distance_errors[smallest_indices]\n",
    "            #print(smallest_error)\n",
    "            \n",
    "            if error < max_error: break\n",
    "        \n",
    "        #print(smallest_indices)\n",
    "        #print(valid_edges[k], valid_edges[l], match_indices[smallest_indices[0]])\n",
    "        \n",
    "        reconstructed_point1 = pos1\n",
    "        reconstructed_point2 = pos2[smallest_indices[1]]\n",
    "        \n",
    "        reconstructed_points = np.concatenate([reconstructed_points, [reconstructed_point1, reconstructed_point2]])\n",
    "        \n",
    "        reconstructed_indices = np.array([0, valid_edges[k][1], valid_edges[l][1 - smallest_indices[1] % 2], valid_edges[k][0], valid_edges[l][smallest_indices[1] % 2], match_indices[smallest_indices[0]]])\n",
    "    \n",
    "    return reconstructed_points, reconstructed_indices, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e7f3f8-ac3c-47ea-95fb-6fffb2462c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_points, reconstructed_indices, error = find_quadrilateral(sorted_distances)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3536bd-3f4e-4b5c-8a26-3026a1315b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae307c-e48c-4aab-97f0-cc45b35b8d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e73f0-3686-4e65-9978-96e8bab7ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_distances[reconstructed_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9fc8fb-d964-455b-a0c9-fbb2ec6fa499",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix(reconstructed_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa472452-1a01-4134-ba6c-5505803f140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_reconstructed_points = align_to_reference_frame(reconstructed_points)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.scatter(original_points[..., 0], original_points[..., 1], 32.0, 'g')\n",
    "\n",
    "plt.scatter(rotated_reconstructed_points[..., 0], rotated_reconstructed_points[..., 1], 4.0, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538369eb-37f8-4d2f-8d7b-fa693dd9fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mask = np.logical_and(\n",
    "    np.logical_and.reduce(i[:, np.newaxis] != reconstructed_indices[1:][np.newaxis, :], axis=-1),\n",
    "    np.logical_and.reduce(j[:, np.newaxis] != reconstructed_indices[1:][np.newaxis, :], axis=-1)\n",
    ")\n",
    "possible_positions = possible_positions[new_mask[mask]]\n",
    "valid_edges = valid_edges[new_mask[mask]]\n",
    "\n",
    "mask = np.logical_and(mask, new_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e44017-68ab-41ea-83fb-d75fee3b54d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, a2 = iter_triu_indices(4)\n",
    "print(a1, a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d394ed7-4e0d-403f-a60e-4e0fa2a5fec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos1 = reconstructed_points[2]\n",
    "\n",
    "for k, pos2 in enumerate(possible_positions):\n",
    "    pos2 = np.stack([pos2, np.stack([-pos2[0], pos2[1]], axis=-1), np.stack([pos2[0], -pos2[1]], axis=-1), -pos2])\n",
    "    \n",
    "    possible_distances = np.sqrt(np.sum((pos1[np.newaxis, :] - pos2) ** 2, axis=-1))\n",
    "    print('possible_distances\\n', possible_distances)\n",
    "    \n",
    "    print('sorted_distances\\n', sorted_distances)\n",
    "    distance_errors = np.abs(possible_distances - sorted_distances[:, np.newaxis])\n",
    "    print('distance_errors\\n', distance_errors)\n",
    "    \n",
    "    smallest_index = np.argmin(distance_errors)\n",
    "    smallest_indices = np.unravel_index(smallest_index, distance_errors.shape)\n",
    "    error = distance_errors[smallest_indices]\n",
    "    print(error)\n",
    "    \n",
    "    if error < max_error: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07879aee-ce20-4bee-b53b-9e9e7878e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_point = pos2[smallest_indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb95efd3-20b3-4dee-bc0d-08d6ff5f26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f79e81-c934-4fa4-9a85-174ec28007d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_points = np.concatenate([reconstructed_points, [reconstructed_point]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b5c803-73b4-48a7-86ed-8dc193688abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797fac8c-52c3-46df-b6f3-75efac606b26",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "quadrilateral_pointss = []\n",
    "quadrilateral_indicess = []\n",
    "quadrilateral_errors = []\n",
    "\n",
    "remaining_sorted_distances = sorted_distances.copy()\n",
    "original_indices = np.arange(len(remaining_sorted_distances))\n",
    "\n",
    "while len(remaining_sorted_distances) >= 6:\n",
    "    print('original_indices\\n', original_indices)\n",
    "    print('remaining_sorted_distances\\n', remaining_sorted_distances)\n",
    "    \n",
    "    quadrilateral_points, quadrilateral_indices, error = find_quadrilateral(remaining_sorted_distances)\n",
    "    quadrilateral_pointss.append(quadrilateral_points)\n",
    "    quadrilateral_indicess.append(quadrilateral_indices)\n",
    "    quadrilateral_errors.append(error)\n",
    "\n",
    "    print('quadrilateral_indices\\n', quadrilateral_indices)\n",
    "    remaining_indices = np.setdiff1d(np.arange(len(remaining_sorted_distances)), quadrilateral_indices[1:])\n",
    "    original_indices = original_indices[remaining_indices]\n",
    "    remaining_sorted_distances = remaining_sorted_distances[remaining_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e0cc4-a946-4099-b01e-c0a8cf4cd5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrilateral_points = np.concatenate([quadrilateral_pointss[0]] + [points[2:] for points in quadrilateral_pointss[1:]])\n",
    "quadrilateral_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17584ef-12db-4192-a9f9-7cafc22eb4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_distances(reconstructed_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c818929d-7f86-4f57-84e7-8d826a519986",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_distances"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d52b5584-e012-4790-8ef8-94d5e64b659b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "quadriliteral_original_point_indices = set()\n",
    "\n",
    "original_distance_matrix = distance_matrix(original_points)\n",
    "for distance in sorted_distances[quadrilateral_indices]:\n",
    "    index = np.argmin(np.abs(original_distance_matrix - distance))\n",
    "    indices = np.unravel_index(index, original_distance_matrix.shape)\n",
    "    quadriliteral_original_point_indices.add(indices[0])\n",
    "    quadriliteral_original_point_indices.add(indices[1])\n",
    "\n",
    "quadriliteral_original_point_indices = list(quadriliteral_original_point_indices)\n",
    "quadriliteral_original_point_indices"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8728c2e5-40ad-4682-892c-7130270a4280",
   "metadata": {},
   "source": [
    "subpoints = original_points[quadriliteral_original_point_indices]\n",
    "distance_matrix(subpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347c6cac-f928-452a-aac5-b2cc1932ceb9",
   "metadata": {},
   "source": [
    "# Try out distance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc989be-42e2-4871-9341-cfd5644c4032",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def generate_distance_matrices(sorted_distances, n):\n",
    "    # Create a template matrix with zeros on the diagonal\n",
    "    template = np.zeros((n, n))\n",
    "    \n",
    "    # Get the indices for the upper triangle (excluding diagonal)\n",
    "    indices = list(zip(*np.triu_indices(n, k=1)))\n",
    "\n",
    "    shuffled_distances = sorted_distances.copy()\n",
    "    np.random.shuffle(shuffled_distances)\n",
    "    \n",
    "    # Generate all permutations of the distances\n",
    "    for perm in permutations(shuffled_distances):\n",
    "        # Create a new matrix for each permutation\n",
    "        matrix = template.copy()\n",
    "        \n",
    "        # Fill the upper triangle with the permuted distances\n",
    "        for (i, j), dist in zip(indices, perm):\n",
    "            matrix[i, j] = dist\n",
    "        \n",
    "        # Make the matrix symmetric\n",
    "        matrix = matrix + matrix.T\n",
    "        \n",
    "        yield matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff82aaf-014c-436a-9aa6-589592e49ba9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def reconstruct_points(sorted_distances, n, max_attempts=1, verbose=False):\n",
    "    lowest_loss = np.inf\n",
    "    reconstructed_points = None\n",
    "\n",
    "    i = 0\n",
    "    try:\n",
    "        for distance_matrix in generate_distance_matrices(sorted_distances, n):\n",
    "            points = mds(distance_matrix, n=n)\n",
    "            loss = loss_function(points, sorted_distances)\n",
    "        \n",
    "            if loss < lowest_loss:\n",
    "                lowest_loss = loss\n",
    "                reconstructed_points = points\n",
    "                if verbose:\n",
    "                    print(loss)\n",
    "        \n",
    "                if lowest_loss < max_error: break\n",
    "    \n",
    "            i += 1\n",
    "            if i == max_attempts: break\n",
    "    except KeyboardInterrupt:\n",
    "        if verbose: print('Keyboard Interrupt', file=sys.stderr)\n",
    "    \n",
    "    return reconstructed_points, lowest_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef92483-d9ad-4024-a1ae-4aaf75626a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstructed_points, loss = reconstruct_points(sorted_distances, num_points, verbose=True, max_attempts=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de28321e-7437-4fcb-9583-3fdaa590d190",
   "metadata": {},
   "source": [
    "# MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f20142a-e369-4d13-877d-af83dcb90b43",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "known_combinations = {}\n",
    "original_indices = np.argsort(np.argsort(distance_matrix(original_points)[np.triu_indices(num_points, k=1)]))\n",
    "current_indices = original_indices # np.arange(len(sorted_distances))\n",
    "np.random.shuffle(current_indices)\n",
    "#current_indices = np.array([20, 15, 25, 18, 27,  0,  4,  9, 12, 24, 10, 17, 11,  3,  6,  7, 14,  5, 13,  1, 23, 16, 22, 19,  8, 26, 21,  2])\n",
    "sorted_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d5c192-1721-445b-9dc5-1833e4f56e33",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i, j in combinations(range(len(current_indices)), 2):\n",
    "    current_indices = original_indices.copy()\n",
    "    \n",
    "    current_indices[i], current_indices[j] = current_indices[j], current_indices[i]\n",
    "    \n",
    "    while tuple(current_indices) not in known_combinations:\n",
    "        current_distances = sorted_distances[current_indices]\n",
    "        current_dist_matrix = squareform(current_distances)\n",
    "        \n",
    "        reconstructed_points = mds(current_dist_matrix, n=num_points)\n",
    "        reconstructed_dist_matrix = distance_matrix(reconstructed_points)\n",
    "        reconstructed_distances = reconstructed_dist_matrix[np.triu_indices(num_points, k=1)]\n",
    "        reconstructed_sorted_distances = np.sort(reconstructed_distances)\n",
    "        \n",
    "        loss = loss_function(reconstructed_points, sorted_distances)\n",
    "        known_combinations[tuple(current_indices)] = loss\n",
    "        print(loss)\n",
    "\n",
    "    break\n",
    "        #current_indices = np.argsort(np.argsort(reconstructed_distances))\n",
    "\n",
    "    break\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3e5c4-fb02-4f89-8416-799c39cb3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_indices = np.argsort(np.argsort(distance_matrix(original_points)[np.triu_indices(num_points, k=1)]))\n",
    "current_indices = original_indices.copy()\n",
    "#np.random.shuffle(current_indices)\n",
    "\n",
    "#current_indices[0], current_indices[3] = current_indices[3], current_indices[0]\n",
    "\n",
    "current_distances = sorted_distances[current_indices]\n",
    "current_dist_matrix = squareform(current_distances)\n",
    "#current_dist_matrix[0][1] += 0.1\n",
    "#current_dist_matrix[1][0] += 0.1\n",
    "current_dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f697b-d247-4588-a67e-0e481560d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = num_points\n",
    "D_squared = current_dist_matrix ** 2\n",
    "J = np.eye(n) - np.ones((n, n)) / n\n",
    "B = -0.5 * J @ D_squared @ J\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(B)\n",
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052acee7-2545-4ae0-898e-3e3a13d92272",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d7d3d-7eb3-4860-a0a1-98debf63ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "correction = 2 * eigenvalues[0] * eigenvectors[:, 0:1] @ eigenvectors[:, 0:1].T  + 2 * eigenvalues[1] * eigenvectors[:, 1:2] @ eigenvectors[:, 1:2].T\n",
    "correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536aa95c-f014-4ef5-a4fd-32c2a5b1226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arbitrary_2 = eigenvalues[2] * eigenvectors[:, 2:3] @ eigenvectors[:, 2:3].T\n",
    "arbitrary_3 = eigenvalues[3] * eigenvectors[:, 3:4] @ eigenvectors[:, 3:4].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985f694-02b3-4188-a1a7-359d1144103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack([np.diag(arbitrary_2), np.diag(arbitrary_3)], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a18d3-da01-4e3a-b63c-b62d64b99361",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.diag(correction).T\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee4d1df-905a-40c8-a14b-c988bc427e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "improvements = np.linalg.pinv(X) @ b * 0.0\n",
    "improvements[0], improvements[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2555de-3b7f-424f-b752-179c2b2e636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arbitrary_2, arbitrary_3, correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04828f59-852a-40d4-8b28-553a840b35f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_correction = correction - improvements[0] * arbitrary_2 - improvements[1] * arbitrary_3\n",
    "optimized_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479de2d9-2adc-4852-abaa-377434d9814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_corrected = D_squared + optimized_correction\n",
    "corrected_dist_matrix = np.sign(D_corrected) * np.sqrt(np.abs(D_corrected))\n",
    "corrected_dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48bd52-5b60-4029-a45b-cd0ae65752e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_dist_matrix - current_dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfaccdd-d6e3-4ddb-85df-91934e70dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_distances, current_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c0ecc2-82f0-4878-a980-fd600c4cd9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bec5fb-2fec-4f75-811c-b60a7b80e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_points = eigenvectors[:, -dim:] @ np.diag(np.sqrt(eigenvalues[-dim:]))\n",
    "reconstructed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106f79e3-ef22-4ce0-98c0-88751e02d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_corrected = B - 0.5 * optimized_correction\n",
    "eigenvalues_corrected, eigenvectors_corrected = np.linalg.eigh(B_corrected)\n",
    "eigenvalues_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840143be-791b-4e1f-96d7-a10d6470371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_points_corrected = eigenvectors_corrected[:, -dim:] @ np.diag(np.sqrt(eigenvalues_corrected[-dim:]))\n",
    "reconstructed_points_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab0252-8d29-4541-ae1f-5b386abbcb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_points = align_to_reference_frame(reconstructed_points)\n",
    "#reconstructed_points_corrected = align_to_reference_frame(reconstructed_points_corrected)\n",
    "\n",
    "print(\"Reconstructed Points:\")\n",
    "print(reconstructed_points)\n",
    "\n",
    "#for i, step_points in enumerate(intermediate_steps):\n",
    "#    intermediate_steps[i] = align_to_reference_frame(step_points)\n",
    "    \n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.scatter(original_points[..., 0], original_points[..., 1], 32.0, 'g')\n",
    "\n",
    "# Visualize the intermediate steps\n",
    "#for i, step in enumerate(intermediate_steps):\n",
    "#    plt.scatter(step[:, 0], step[:, 1], 1.0, 'r', alpha=i / len(intermediate_steps))\n",
    "\n",
    "plt.scatter(reconstructed_points[..., 0], reconstructed_points[..., 1], 4.0, 'b')\n",
    "#plt.scatter(reconstructed_points_corrected[..., 0], reconstructed_points_corrected[..., 1], 4.0, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5955acbd-cfbe-4538-b594-f40a28e84fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_distances = sorted_distances[current_indices]\n",
    "current_dist_matrix = squareform(current_distances)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6708a59-03e1-4eb3-91e8-e173fc67cf66",
   "metadata": {},
   "source": [
    "print([eigenvectors[:, 0].T @ (B @ eigenvectors[:, 0]),\n",
    "eigenvectors[:, 1].T @ (B @ eigenvectors[:, 1]),\n",
    "eigenvectors[:, 2].T @ (B @ eigenvectors[:, 2]),\n",
    "eigenvectors[:, 3].T @ (B @ eigenvectors[:, 3]),\n",
    "eigenvectors[:, 4].T @ (B @ eigenvectors[:, 4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87fcae0-d7e6-4294-8abb-78e97454dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_distances = sorted_distances[current_indices]\n",
    "current_dist_matrix = squareform(current_distances)\n",
    "\n",
    "reconstructed_points = mds(current_dist_matrix, n=num_points)\n",
    "reconstructed_dist_matrix = distance_matrix(reconstructed_points)\n",
    "reconstructed_distances = reconstructed_dist_matrix[np.triu_indices(num_points, k=1)]\n",
    "reconstructed_sorted_distances = np.sort(reconstructed_distances)\n",
    "\n",
    "loss = loss_function(reconstructed_points, sorted_distances)\n",
    "known_combinations[tuple(current_indices)] = loss\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e2178-99e4-40e2-941e-c10f51820dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_error = current_distances - reconstructed_distances\n",
    "reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bac24c-6ba5-41d8-a4ee-d113e49a2bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = sorted_distances - reconstructed_sorted_distances\n",
    "sort_indices = np.argsort(current_distances)\n",
    "unsort_indices = np.argsort(sort_indices)\n",
    "unsorted_gradients = gradients[unsort_indices]\n",
    "unsorted_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ffe917-1118-4b8b-bf5b-49cc5adf31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_error - unsorted_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c258fba1-3cb3-4630-aa16-3ee32e572927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a526577-88dc-4f3c-ab4c-4003b9d8afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_indices = np.argsort(unsorted_gradients)\n",
    "#max_indices = np.flip(min_indices[len(min_indices)//2:])\n",
    "#min_indices = min_indices[:len(min_indices)//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f63574-ec21-4e58-810e-e83d70b21bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a95f6-86f7-4aa1-9eaa-b831ed0245cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c56c62-ceb0-4af9-b7e1-0b53d36f3b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_indices[min_indices], current_indices[max_indices] = current_indices[max_indices], current_indices[min_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743ecd9-a39a-4b59-8f92-534e5f6cadb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e389c2be-6e61-4b5f-8586-33ae236f8082",
   "metadata": {},
   "outputs": [],
   "source": [
    "for combination, loss in known_combinations.items():\n",
    "    print(combination, loss)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f92a95ee-233d-4571-be17-68694e829704",
   "metadata": {},
   "source": [
    "# Create a mapping from sorted to unsorted indices\n",
    "sort_indices = np.argsort(current_distances)\n",
    "unsort_indices = np.argsort(sort_indices)\n",
    "print(sort_indices)\n",
    "print(unsort_indices)\n",
    "\n",
    "# Map gradients back to original distance matrix entries\n",
    "unsorted_gradients = gradients[unsort_indices]\n",
    "unsorted_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4163d632-be47-4190-bb1e-7bef3bee8135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b18a0-b3e6-43a7-b9c6-69e3368fe287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_points(sorted_distances, n, verbose=False):\n",
    "    distances = sorted_distances.copy()\n",
    "    try:\n",
    "        for _ in range(10):...\n",
    "        distance_matrix = squareform(distances)\n",
    "        reconstructed_points = mds(distance_matrix, n=n)\n",
    "        loss = loss_function(points, sorted_distances)\n",
    "    \n",
    "        if verbose: print(loss)\n",
    "        if loss < max_error: break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        if verbose: print('Keyboard Interrupt', file=sys.stderr)\n",
    "    \n",
    "    return reconstructed_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc35b2-fe00-43e0-b7e0-73761764f32e",
   "metadata": {},
   "source": [
    "# Triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb90265-7c99-43f8-b22e-dd89f578322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangle_inequality(a, b, c):\n",
    "    return a + b >= c and b + c >= a and c + a >= b\n",
    "\n",
    "def find_valid_triangles(sorted_distances):\n",
    "    n = len(sorted_distances)\n",
    "    for i, j, k in combinations(reversed(range(n)), 3):\n",
    "        a, b, c = sorted_distances[i], sorted_distances[j], sorted_distances[k]\n",
    "        if triangle_inequality(a, b , c):\n",
    "            yield (i, j, k), np.sort([a, b, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761bde9-9db0-4316-a926-f80c09cc2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3134ac-90eb-425c-83c6-44eea749a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = []\n",
    "\n",
    "n = 3\n",
    "for indices, triangle in find_valid_triangles(sorted_distances):\n",
    "    print(indices, triangle)\n",
    "    reconstructed_points, error = reconstruct_points(triangle, n)\n",
    "    triplets.append(reconstructed_points)\n",
    "    triplets.append(-reconstructed_points)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af1911-aea1-4c66-bfbb-eb8d3bd8533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4  # We're looking for 4 points\n",
    "subset_size = 6\n",
    "\n",
    "for distances_subset in combinations(sorted_distances, subset_size):\n",
    "    print(distances_subset)\n",
    "    if all(triangle_inequality(distances_subset[x], distances_subset[y], distances_subset[z]) for x in range(4) for y in range(x+1, 5) for z in range(y+1, 6)):\n",
    "        print(True)\n",
    "    else:\n",
    "        print(False)\n",
    "    \n",
    "    # Reconstruct points using this subset of distances\n",
    "    distances_subset = np.array(distances_subset)\n",
    "    reconstructed_points, error = reconstruct_points(distances_subset, n)\n",
    "\n",
    "    print(error)\n",
    "    if error < max_error: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84298024-dffb-46ad-be2c-e164904eea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf5089a-647e-4615-acf7-ea54cfee9d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_point(partial_solution, all_distances, error_threshold=1e-6):\n",
    "    \"\"\"\n",
    "    Try to find the next point to add to the partial solution.\n",
    "    \n",
    "    :param partial_solution: Tuple of (points, distances) for the current partial solution\n",
    "    :param all_distances: List of all distances in the original problem\n",
    "    :param error_threshold: Maximum allowed error for a successful addition\n",
    "    :return: Tuple of (new_points, new_distances, success)\n",
    "    \"\"\"\n",
    "    points, accounted_distances = partial_solution\n",
    "    n = len(points)\n",
    "    \n",
    "    # Find distances that are not yet accounted for\n",
    "    unaccounted_distances = set(all_distances) - set(accounted_distances)\n",
    "    \n",
    "    # Try adding a new point at different positions\n",
    "    for new_distances in combinations(unaccounted_distances, n):\n",
    "        new_point = trilaterate(points, new_distances)\n",
    "        if new_point is not None:\n",
    "            new_points = np.vstack((points, new_point))\n",
    "            new_all_distances = pdist(new_points)\n",
    "            \n",
    "            if is_valid_merge(new_all_distances, all_distances, error_threshold):\n",
    "                new_accounted_distances = set(accounted_distances) | set(new_distances)\n",
    "                return new_points, list(new_accounted_distances), True\n",
    "    \n",
    "    return None, None, False\n",
    "\n",
    "def trilaterate(points, distances):\n",
    "    \"\"\"\n",
    "    Find a new point given its distances to existing points.\n",
    "    This is a simplified trilateration and might not work in all cases.\n",
    "    \"\"\"\n",
    "    A = 2 * (points[1:] - points[0])\n",
    "    b = distances[0]**2 - np.sum(points[0]**2) + np.sum(points[1:]**2, axis=1) - np.array(distances[1:])**2\n",
    "    try:\n",
    "        return np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "    except np.linalg.LinAlgError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda0534-821b-4379-a678-c9dba3364f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
