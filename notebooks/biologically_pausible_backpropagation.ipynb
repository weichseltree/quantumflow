{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess data\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Flatten images for input layer\n",
    "x_train = x_train.reshape(-1, 28 * 28)\n",
    "x_test = x_test.reshape(-1, 28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints, input_dim = x_train.shape\n",
    "datapoints, input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, output_dim = y_train.shape\n",
    "output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights_and_biases(input_dim, hidden_units, output_dim):\n",
    "  \"\"\"\n",
    "  Initializes weights and biases for a densely connected neural network.\n",
    "\n",
    "  Args:\n",
    "    input_dim: The dimension of the input layer.\n",
    "    hidden_units: A list of integers representing the number of units in each hidden layer.\n",
    "    output_dim: The dimension of the output layer.\n",
    "\n",
    "  Returns:\n",
    "    A tuple containing two lists:\n",
    "      - weights: A list of tensors representing the weights for each layer.\n",
    "      - biases: A list of tensors containing the biases for each layer.\n",
    "  \"\"\"\n",
    "  weights = []\n",
    "  biases = []\n",
    "\n",
    "  # Initialize weights for the first layer (input to first hidden)\n",
    "  weights.append(tf.random.normal([input_dim, hidden_units[0]], mean=0.0, stddev=0.01))\n",
    "  biases.append(tf.zeros([hidden_units[0]]))\n",
    "\n",
    "  # Initialize weights and biases for hidden layers\n",
    "  for i in range(1, len(hidden_units)):\n",
    "    weights.append(tf.random.normal([hidden_units[i-1], hidden_units[i]], mean=0.0, stddev=0.01))\n",
    "    biases.append(tf.zeros([hidden_units[i]]))\n",
    "\n",
    "  # Initialize weights for the last layer (last hidden to output)\n",
    "  weights.append(tf.random.normal([hidden_units[-1], output_dim], mean=0.0, stddev=0.01))\n",
    "  biases.append(tf.zeros([output_dim]))\n",
    "\n",
    "  return weights, biases\n",
    "\n",
    "hidden_units = [256, 128]\n",
    "output_dim = 10\n",
    "\n",
    "weights, biases = initialize_weights_and_biases(input_dim, hidden_units, output_dim)\n",
    "\n",
    "print(\"weights:\", [weight.shape for weight in weights])\n",
    "print(\"biases:\", [bias.shape for bias in biases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(inputs, weights, biases):\n",
    "  \"\"\"\n",
    "  Performs a forward pass through a densely connected neural network with ReLU activation.\n",
    "\n",
    "  Args:\n",
    "    inputs: A tensor of shape (batch_size, input_dim) representing the input data.\n",
    "    weights: A list of tensors representing the weights for each layer.\n",
    "    biases: A list of tensors representing the biases for each layer.\n",
    "\n",
    "  Returns:\n",
    "    A list of tensors representing the activations after each layer, \n",
    "    including the input layer.\n",
    "  \"\"\"\n",
    "  activations = [inputs]\n",
    "  for w, b in zip(weights, biases):\n",
    "    layer_output = tf.matmul(activations[-1], w) + b\n",
    "    activations.append(tf.nn.relu(layer_output))\n",
    "  return activations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform a single training step with your custom backpropagation\n",
    "def train_step(images, labels):\n",
    "  ...\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(5):\n",
    "  for images, labels in zip(flat_x_train, y_train):\n",
    "    train_step(images, labels)\n",
    "\n",
    "# Evaluate model performance\n",
    "test_loss, test_acc = model.evaluate(flat_x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
